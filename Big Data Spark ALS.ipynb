{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing Collaborative Filtering with Spark ALS\n",
        "\n",
        "\n",
        "This notebook implements a Collaborative Filtering recommendation system using Apache Sparkâ€™s ALS (Alternating Least Squares) algorithm. Given the inefficiency of SVD (Singular Value Decomposition) for large datasets, we leverage Spark to optimize performance and scalability. The workflow includes:\n",
        "* Data loading & preprocessing with PySpark.\n",
        "* Exploratory Data Analysis (EDA) to understand user-item interactions.\n",
        "* Training & evaluating an ALS model to predict user preferences.\n",
        "* Generating top-3 product recommendations for each user."
      ],
      "metadata": {
        "id": "Y7hMv3iNXWNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Import necessary libraries:  PySpark offers distributed computing features that are critical for managing massive data processing."
      ],
      "metadata": {
        "id": "46Iu0Wep64cW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2Bru_zvJWsK",
        "outputId": "5c4f9d3e-73e8-44a1-e5fc-e45af3bb2b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.4)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# Install PySpark\n",
        "!pip install pyspark\n",
        "\n",
        "# Import required libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, explode, count, mean , desc\n",
        "import requests\n",
        "import os\n",
        "\n",
        "# Initialize ALS model\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.sql.functions import explode"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark Session Initialization\n",
        "The first step in PySpark programming is to create a Spark session.  Our dispersed computations have a unified context thanks to this session."
      ],
      "metadata": {
        "id": "F2fCoIEPXxa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize session\n",
        "spark = SparkSession.builder.appName(\"Collaborative Filtering with ALS\").getOrCreate()"
      ],
      "metadata": {
        "id": "WFwbMwIUMByi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Integration\n"
      ],
      "metadata": {
        "id": "DQxw2WhMX6Vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = spark.read.csv(\"transactions.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "dhlVABKBNH-X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display schema\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHXx2wN196RA",
        "outputId": "caf8ce76-ff00-4e2a-9759-f51540209575"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- User: integer (nullable = true)\n",
            " |-- Product: integer (nullable = true)\n",
            " |-- Interaction: integer (nullable = true)\n",
            " |-- ProductName: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)\n"
      ],
      "metadata": {
        "id": "9VxldoQuYwLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count total records\n",
        "print(\"Total records:\", df.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfwbpjt69uQO",
        "outputId": "22f81cfe-b25c-460e-c1dd-a8550433d5ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total records: 1000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics\n",
        "print(\"\\nSummary Statistics:\")\n",
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkA2fusz-jlw",
        "outputId": "d22e0503-fd0d-4a8b-ef48-647d001c870b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary Statistics:\n",
            "+-------+------------------+------------------+-----------------+--------------------+\n",
            "|summary|              User|           Product|      Interaction|         ProductName|\n",
            "+-------+------------------+------------------+-----------------+--------------------+\n",
            "|  count|           1000000|           1000000|          1000000|             1000000|\n",
            "|   mean|      50014.595087|          5.498436|         2.500161|                NULL|\n",
            "| stddev|28864.277886609754|2.8710903498608187|1.117490591845948|                NULL|\n",
            "|    min|                 1|                 1|                1|            Car Loan|\n",
            "|    max|            100000|                10|                4|Travel Rewards Cr...|\n",
            "+-------+------------------+------------------+-----------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#count NULL values in each column\n",
        "df.select([(count(col(c)) - count(col(c))).alias(f\"missing_{c}\") for c in df.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjCg-TX3-C_X",
        "outputId": "13acb372-fd0f-4b13-982b-49252ac0c437"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------------+-------------------+-------------------+\n",
            "|missing_User|missing_Product|missing_Interaction|missing_ProductName|\n",
            "+------------+---------------+-------------------+-------------------+\n",
            "|           0|              0|                  0|                  0|\n",
            "+------------+---------------+-------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#counts non-null values for each column.\n",
        "df.select([count(col(c)).alias(c) for c in df.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfLZmHyB-JCs",
        "outputId": "c58ad254-6cea-41fe-87c0-432c350df8ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-----------+-----------+\n",
            "|   User|Product|Interaction|ProductName|\n",
            "+-------+-------+-----------+-----------+\n",
            "|1000000|1000000|    1000000|    1000000|\n",
            "+-------+-------+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Since each column has 1,000,000 values, it means no missing values exist in the transactions data."
      ],
      "metadata": {
        "id": "SnP6uuG--MzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique Users and Products\n",
        "df.select(count(\"User\").alias(\"Unique Users\"), count(\"Product\").alias(\"Unique Products\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPBL_wFX-R51",
        "outputId": "d3ada6bb-8094-46ee-d324-55427c355f1f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------------+\n",
            "|Unique Users|Unique Products|\n",
            "+------------+---------------+\n",
            "|     1000000|        1000000|\n",
            "+------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of Interactions (PySpark Aggregation)\n",
        "df.groupBy(\"Interaction\").count().orderBy(\"Interaction\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsWWSxD0-Vcx",
        "outputId": "f6d943b7-7742-4c34-91f7-eaddd5bdea02"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------+\n",
            "|Interaction| count|\n",
            "+-----------+------+\n",
            "|          1|249792|\n",
            "|          2|249855|\n",
            "|          3|250753|\n",
            "|          4|249600|\n",
            "+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Most popular product\n",
        "print(\"\\nTop 5 Products by Interaction Count:\")\n",
        "df.groupBy(\"Product\", \"ProductName\") \\\n",
        "    .count() \\\n",
        "    .orderBy(desc(\"count\")) \\\n",
        "    .show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vrwkdMp-5ja",
        "outputId": "d818981c-77f6-450a-c015-1e748b8ad7df"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 5 Products by Interaction Count:\n",
            "+-------+--------------------+------+\n",
            "|Product|         ProductName| count|\n",
            "+-------+--------------------+------+\n",
            "|      2|Cashback Credit Card|100789|\n",
            "|      6|       Personal Loan|100307|\n",
            "|      7|       Fixed Deposit|100080|\n",
            "|      3| Student Credit Card|100039|\n",
            "|      9|Mutual Fund - Hig...| 99917|\n",
            "+-------+--------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detecting Outliers using IQR Method\n",
        "summary = df.selectExpr(\"percentile_approx(Interaction, 0.25) as Q1\", \"percentile_approx(Interaction, 0.75) as Q3\").collect()\n",
        "Q1 = summary[0]['Q1']\n",
        "Q3 = summary[0]['Q3']\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "print(f\"IQR Method: Lower Bound = {lower_bound}, Upper Bound = {upper_bound}\")\n",
        "\n",
        "outliers_iqr = df.filter((col(\"Interaction\") < lower_bound) | (col(\"Interaction\") > upper_bound))\n",
        "print(\"Outliers detected using IQR method:\")\n",
        "outliers_iqr.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFG8Kt0s_fu3",
        "outputId": "662c33e3-a9bd-4674-a658-660270719cc8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IQR Method: Lower Bound = 0.5, Upper Bound = 4.5\n",
            "Outliers detected using IQR method:\n",
            "+----+-------+-----------+-----------+\n",
            "|User|Product|Interaction|ProductName|\n",
            "+----+-------+-----------+-----------+\n",
            "+----+-------+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proceed with ALS Processing\n",
        "ALS requires numerical user IDs, product IDs, and interaction values."
      ],
      "metadata": {
        "id": "qgfb3K7TY7r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns\n",
        "df= df.withColumnRenamed(\"User\", \"userId\").withColumnRenamed(\"Product\", \"itemId\").withColumnRenamed(\"Interaction\", \"rating\")"
      ],
      "metadata": {
        "id": "8HJIEFMJ__5E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop missing values\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "1-jiC6i5AWr_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure correct data types\n",
        "df= df.withColumn(\"userId\", col(\"userId\").cast(\"integer\"))\n",
        "df = df.withColumn(\"itemId\", col(\"itemId\").cast(\"integer\"))\n",
        "df = df.withColumn(\"rating\", col(\"rating\").cast(\"integer\"))"
      ],
      "metadata": {
        "id": "tB5mEisfAZRP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split (80-20)\n",
        "(train, test) = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(\"\\nTraining Data Count:\", train.count())\n",
        "print(\"Test Data Count:\", test.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5ZWH3bLAegF",
        "outputId": "0cc3f3b0-42ee-4d95-8219-176861a2e3a8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Data Count: 799963\n",
            "Test Data Count: 200037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ALS (Alternating Least Squares ) Model Implementation\n",
        " ALS is particularly effective for large-scale recommendation systems due to its parallel computation capabilities."
      ],
      "metadata": {
        "id": "QGLcglMVZGrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure and train ALS model (Number of iterations ,Regularization parameter,Number of latent factors,Handle new users/products )\n",
        "als = ALS(\n",
        "    userCol=\"userId\", itemCol=\"itemId\", ratingCol=\"rating\",\n",
        "    maxIter=10, regParam=0.1, rank=10,\n",
        "    coldStartStrategy=\"drop\"\n",
        ")"
      ],
      "metadata": {
        "id": "SFRdv3i-A3a4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model = als.fit(train)"
      ],
      "metadata": {
        "id": "YB5jWeucBhh4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation\n",
        "Use Root Mean Square Error (RMSE), a common recommendation system statistic that gauges prediction accuracy, to assess our model's performance."
      ],
      "metadata": {
        "id": "_gO13EWaZSDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "# Generate predictions\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calculate RMSE\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"\\nRoot Mean Square Error (RMSE): {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8fMahB8CI9H",
        "outputId": "16e120e1-345e-4246-9ebc-12e44ba63667"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Root Mean Square Error (RMSE): 1.3136498946620652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate top-3 recommendations for each user as a dataframe\n"
      ],
      "metadata": {
        "id": "3CLjIWZYZbTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate top-3 recommendations\n",
        "userRecs = model.recommendForAllUsers(3)\n",
        "\n",
        "# Format recommendations\n",
        "recommendations = userRecs.select(\n",
        "    col(\"userId\"),\n",
        "    explode(col(\"recommendations\")).alias(\"rec\")\n",
        ").select(\n",
        "    \"userId\",\n",
        "    col(\"rec.itemId\").alias(\"recommended_item\"),\n",
        "    col(\"rec.rating\").alias(\"predicted_interaction\")\n",
        ")\n",
        "\n",
        "# Add product names\n",
        "final_recommendations = recommendations.join(\n",
        "    df.select(\"itemId\", \"ProductName\").distinct(),\n",
        "    recommendations.recommended_item == df.itemId\n",
        ").select(\n",
        "    \"userId\",\n",
        "    \"recommended_item\",\n",
        "    \"ProductName\",\n",
        "    \"predicted_interaction\"\n",
        ")\n",
        "\n",
        "# Display sample recommendations\n",
        "print(\"\\nSample Recommendations:\")\n",
        "final_recommendations.show(5)\n",
        "\n",
        "# Save recommendations\n",
        "final_recommendations.coalesce(1).write \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .csv(\"recommendations\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf2Om1qLSjoL",
        "outputId": "2ea4c258-a510-4b41-8325-ef089ede8286"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Recommendations:\n",
            "+------+----------------+--------------------+---------------------+\n",
            "|userId|recommended_item|         ProductName|predicted_interaction|\n",
            "+------+----------------+--------------------+---------------------+\n",
            "|     3|               1|Travel Rewards Cr...|             2.777319|\n",
            "|     9|               1|Travel Rewards Cr...|            1.8132145|\n",
            "|    15|               1|Travel Rewards Cr...|             2.421748|\n",
            "|    26|               1|Travel Rewards Cr...|            2.8983932|\n",
            "|    41|               1|Travel Rewards Cr...|            2.8494582|\n",
            "+------+----------------+--------------------+---------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleanup and Session Termination\n",
        "clean up resources and close the Spark session."
      ],
      "metadata": {
        "id": "q9Wg4v3CZoV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop Spark session\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "awwVMG3LS0Ag"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "In this project, we successfully optimized a Collaborative Filtering recommendation system using Apache Sparkâ€™s ALS (Alternating Least Squares) algorithm, overcoming the limitations of SVD (Singular Value Decomposition) for large-scale datasets.\n",
        "\n",
        "### Key Achievements:\n",
        "* Efficient Data Processing:\n",
        "\n",
        "Instead of Pandas, we used PySpark to load and preprocess 1 million transactions, ensuring scalability.\n",
        "Basic Exploratory Data Analysis (EDA) was performed to understand user-item interactions.\n",
        "* Performance Improvement with ALS:\n",
        "\n",
        "SVD was slow and memory-intensive, making it impractical for our large dataset.\n",
        "ALS, designed for distributed computing, significantly improved scalability and efficiency on sparse user-item matrices.\n",
        "* Model Evaluation & Recommendations:\n",
        "\n",
        "Root Mean Square Error (RMSE): 1.31, indicating a good balance between accuracy and generalization.\n",
        "Generated personalized recommendations for users, with predictions like:\n",
        "\n",
        "| userId | recommended_item | ProductName                  | predicted_interaction |\n",
        "|--------|-----------------|-----------------------------|-----------------------|\n",
        "| 3      | 1               | Travel Rewards Credit Card  | 2.77                  |\n",
        "| 9      | 1               | Travel Rewards Credit Card  | 1.81                  |\n",
        "\n",
        "* Scalability & Real-World Application:\n",
        "\n",
        "Spark ALS enabled parallel processing, making it practical for real-time recommendation systems.\n",
        "The final recommendations were saved to a CSV, allowing seamless integration into business applications.\n",
        "\n",
        "By leveraging Apache Sparkâ€™s ALS, we successfully optimized collaborative filtering for large-scale recommendation systems. This approach can be extended to real-world applications, such as personalized product recommendations, customer retention strategies, and targeted marketing campaigns.\n"
      ],
      "metadata": {
        "id": "iTvHwwhdaRAR"
      }
    }
  ]
}
